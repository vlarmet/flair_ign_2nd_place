{"cells":[{"cell_type":"markdown","source":["# FINETUNE SEGFORMER on 5 channels images (Tensorflow)\n","\n","---\n","\n","<a target=\"_blank\" href=\"https://colab.research.google.com/drive/1UzBqcmHcXeIWdJFUpyfbXNKRoOOQP7EB\">\n","  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n","</a>\n","\n","https://huggingface.co/docs/transformers/model_doc/segformer\n"],"metadata":{"id":"sLt7WhsAcGn5"}},{"cell_type":"markdown","source":["<img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/segformer_architecture.png\"  width=\"600\">\n"],"metadata":{"id":"V5vcO9SjLR1p"}},{"cell_type":"markdown","source":["## Install dependencies\n","\n","---\n"],"metadata":{"id":"khxJoNqicmEh"}},{"cell_type":"code","source":["!pip install transformers\n","!pip install split-folders"],"metadata":{"id":"pllDpAneKXAs"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vD89-H3prNH7"},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","from glob import glob\n","from scipy.io import loadmat\n","import matplotlib.pyplot as plt\n","import matplotlib\n","import albumentations as aug\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras import backend as K\n","from osgeo import gdal\n","import pandas as pd\n","import gc\n","import math\n","import json\n","# from segmentation_models import Unet\n","from transformers import TFSegformerForSemanticSegmentation, SegformerConfig\n","import shutil\n","import splitfolders\n","from skimage import img_as_float"]},{"cell_type":"markdown","source":["## check GPU\n","\n","---\n","\n"],"metadata":{"id":"-SJAVp7ecSqI"}},{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"metadata":{"id":"KVCeNbyUXKF5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Connect do GoogleDrive\n","\n","---\n","\n"],"metadata":{"id":"dC7m1xgHokgv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"VlgP4yyUqQWw"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"markdown","source":["## Unzip training data\n","\n","---\n","\n"],"metadata":{"id":"XL6RZox_-PRX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"gW8ZmnThPD8n"},"outputs":[],"source":["!unzip /content/gdrive/MyDrive/flair-one/data/flair-one_train.zip"]},{"cell_type":"markdown","source":["## Split data for train/val\n","\n","---\n","\n"],"metadata":{"id":"GnLDWesUBvEI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"KTazzNqgBvEI"},"outputs":[],"source":["! mkdir \"/content/temp\"\n","! mkdir \"/content/data\"\n","! mkdir \"/content/data/masks\"\n","! mkdir \"/content/data/images\"\n","\n","# Chemin du dossier source\n","src_folder = '/content/train/'\n","\n","# Chemin du dossier de destination\n","dst_folder = '/content/temp/'\n","\n","for subdir, dirs, files in os.walk(src_folder):\n","    for file in files:\n","        src_file = os.path.join(subdir, file)\n","        dst_file = os.path.join(dst_folder, file)\n","        shutil.move(src_file, dst_folder)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O3v4rkiFBvEI"},"outputs":[],"source":["cd temp"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LjDlXeqrBvEJ"},"outputs":[],"source":["!mv MSK*.tif /content/data/masks/\n","!mv  IMG*.tif /content/data/images/\n","\n","splitfolders.ratio(\"/content/data/\", seed=1337, ratio=(.99, .01), move=True) # default values"]},{"cell_type":"markdown","source":["## data augmentation\n","\n","---\n","\n"],"metadata":{"id":"8SEH2A12dAXI"}},{"cell_type":"code","source":["MEAN = np.array([0.44050665, 0.45704361, 0.42254708, 0.40987858, 0.06875153])\n","STD = np.array([0.20264351, 0.1782405 , 0.17575739, 0.15510736, 0.11867123])\n","\n","\n","train_transform = aug.Compose([\n","    aug.VerticalFlip(p=0.5),\n","    aug.HorizontalFlip(p=0.5),\n","    aug.RandomRotate90(p=0.5),\n","    aug.Normalize(mean=MEAN, std=STD),\n","\n","])\n","\n","test_transform = aug.Compose([\n","    aug.Normalize(mean=MEAN, std=STD),\n","])\n"],"metadata":{"id":"gaOqYiP9yfRu"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hPEnnLGnrNIN"},"outputs":[],"source":["with open(metadata) as f:\n","    data = json.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_K7rjqAlrNIO"},"outputs":[],"source":["np.random.seed(random_state)\n","\n","def to_categorical(a):\n","  classes = np.arange(13)\n","  a_array = [(a == v) for v in classes]  #extract\n","  a = np.stack(a_array,axis=-1).astype(\"float\")  #stack\n","  return a\n","\n","def read_image(image_path, mask=False):\n","    im = gdal.Open(image_path)\n","    if mask:\n","        image = im.ReadAsArray()\n","        image = np.where(np.isin(image, [19,13,14,15,16,17,18]), 13, image) - 1\n","    else:\n","        image = im.ReadAsArray().astype(np.float32)     \n","        # image = image / 255.0\n","\n","\n","    im = None\n","    return image\n","\n","\n","def get_metadata(img_id):\n","  CAMERAS = [\"CAMERA#030\", \"UCE-M3-f120-s06\", \"UCE-M3-f120-s08\", \"UCE-M3-f120-s07\", \"CAMERA#020\", \"CAMERA#017\", \"UCE-M3-f120\", \"CAMERA#034\", \"UCE-M3-f100\"]\n","  res = []\n","  dat = data[img_id]\n","  # x, y, z\n","  res.append((dat[\"patch_centroid_x\"] -  1.352762e+05)/ (1.079966e+06 - 1.352762e+05))\n","  res.append((dat[\"patch_centroid_y\"] -  6.157188e+06)/ (17.030514e+06 - 6.157188e+06))\n","  res.append((dat[\"patch_centroid_z\"] -  -109.949997)/ (3164.909912 - -109.949997))\n","  # day\n","  x = np.sin(2 * np.pi * float(dat[\"date\"][8:])/31.0)\n","  y = np.cos(2 * np.pi * float(dat[\"date\"][8:])/31.0)\n","  res.append(x)\n","  res.append(y)\n","  #month\n","  x = np.sin(2 * np.pi * float(dat[\"date\"][5:7])/12.0)\n","  y = np.cos(2 * np.pi * float(dat[\"date\"][5:7])/12.0)\n","  res.append(x)\n","  res.append(y)\n","  #hour\n","  x = np.sin(2 * np.pi * float(dat[\"time\"][:2])/24.0)\n","  y = np.cos(2 * np.pi * float(dat[\"time\"][:2])/24.0)\n","  res.append(x)\n","  res.append(y)\n","  #camera\n","  cam = [1 if dat[\"camera\"] == cam else 0 for cam in CAMERAS]\n","  res = res + cam\n","  return np.array(res).astype(np.float32)"]},{"cell_type":"markdown","source":["## Define a class for the image segmentation dataset\n","\n","---\n","\n"],"metadata":{"id":"zcwHs0CnCwfY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6cF0Tqx5rNIP"},"outputs":[],"source":["train_img_paths = []\n","for dep in os.listdir(\"/content/temp/output/train\"):\n","    for img in os.listdir(\"/\".join([\"/content/temp/output/train\", \"images\"])):\n","        img_path = \"/\".join([\"/content/temp/output/train\", \"images\", img])\n","        msk_path = img_path.replace(\"/images/IMG_\", \"/masks/MSK_\")\n","        train_img_paths.append((img_path, msk_path))\n","\n","val_img_paths = []\n","for dep in os.listdir(\"/content/temp/output/val\"):\n","    for img in os.listdir(\"/\".join([\"/content/temp/output/val\", \"images\"])):\n","        img_path = \"/\".join([\"/content/temp/output/val\", \"images\", img])\n","        msk_path = img_path.replace(\"/images/IMG_\", \"/masks/MSK_\")\n","        val_img_paths.append((img_path, msk_path))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NWrQw0uGrNIQ"},"outputs":[],"source":["class Datagen(tf.keras.utils.Sequence):\n","    def __init__(self, path_list, batch_size, random_state, val_rate, train, return_x_only = False, transforms=None):\n","\n","        self.batch_size = batch_size\n","        self.random_state = random_state\n","        self.ids = np.array(path_list)\n","        self.train = train\n","        self.transforms = transforms\n","        self.rng = np.random.RandomState(random_state)\n","        self.rng.shuffle(self.ids)\n","        if train:\n","            self.ids = self.ids[:round((1 - val_rate) * len(self.ids))]\n","        else :\n","            self.ids = self.ids[round((1 - val_rate) * len(self.ids)):]\n","        self.current_index = 0\n","        self.num_batch = 0\n","        self.return_x_only = return_x_only\n"," \n","\n","    def __augment(self, x, y):\n","        return x, y\n","\n","    def __len__(self):\n","        ''' return total number of batches '''\n","        return math.floor(len(self.ids)/self.batch_size)\n","\n","    def on_epoch_end(self):\n","        self.current_index = 0\n","        self.num_batch = 0\n","        if self.train : self.rng.shuffle(self.ids)\n","        ''' shuffle data after every epoch '''\n","        # fix on epoch end it's not working, adding shuffle in len for alternative\n","        pass\n","\n","    def __getitem__(self, idx):\n","        \n","        if self.num_batch == self.__len__() - 1 or self.current_index > len(self.ids) - self.batch_size:\n","            self.current_index = 0\n","            self.num_batch = 0\n","            if self.train : self.rng.shuffle(self.ids)\n","\n","        \n","\n","        # list of current batch indexes\n","        batch_ids = self.ids[self.current_index:(self.current_index + self.batch_size)]\n","\n","        x = []\n","        y = []\n","        \n","        for img_path, msk_path in batch_ids:\n","            x.append(read_image(img_path, mask=False))\n","            y.append(read_image(msk_path, mask=True))\n","  \n","\n","        if len(x) == 0:\n","            print(self.current_index)\n","\n","            for img_path, msk_path in self.ids[0:(0 + self.batch_size)]:\n","                x.append(read_image(img_path, mask=False))\n","                y.append(read_image(msk_path, mask=True))\n","        \n","               \n"," \n","\n","        x = np.concatenate([np.expand_dims(img, axis=0) for img in x], axis=0)\n","        y = np.concatenate([np.expand_dims(msk, axis=0) for msk in y], axis=0)\n","\n","\n","        self.current_index += self.batch_size\n","        self.num_batch += 1\n","        \n","        \n","        # augmentation\n","        # https://github.com/albumentations-team/albumentations/issues/816\n","        if self.transforms is not None:\n","            for i in range (0,self.batch_size):\n","                # print (i, x[i].shape, y[i].shape)\n","                sample = {\"image\" : x[i].swapaxes(0, 2).swapaxes(0, 1), \"mask\": y[i]}\n","                transformed_sample = self.transforms(**sample)\n","\n","                x[i] = transformed_sample[\"image\"].swapaxes(0, 2).swapaxes(1, 2)\n","                y[i] = transformed_sample[\"mask\"]\n","                # print (i, x[i].shape, y[i].shape)\n","        \n","\n","        if self.return_x_only:\n","            return tf.convert_to_tensor(x)\n","        else:\n","            return tf.convert_to_tensor(x), tf.convert_to_tensor(y)\n","\n","        "]},{"cell_type":"markdown","metadata":{"id":"Plz_xtW1VXRP"},"source":["# Fine-tune a SegFormer model\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"3ci_NXUQV02W"},"source":["## Load the model to fine-tune"]},{"cell_type":"code","source":["model2 = TFSegformerForSemanticSegmentation.from_pretrained(\n","    \"nvidia/mit-b0\",\n","    num_labels=13\n",")\n","\n","new_config = model2.config\n","# print(new_config)\n","\n","new_config.num_channels = 5\n","\n","model = TFSegformerForSemanticSegmentation(new_config)\n","model.build(input_shape=(1,5,512,512))\n","\n","\n","\n","wts = model.get_weights()\n","wts2 = model2.get_weights()\n","\n","for i in range(len(wts)):\n","    if wts[i].shape != wts2[i].shape:\n","        print(i, wts[i].shape,wts2[i].shape)\n","\n","wts2[0] = np.concatenate([wts2[0], wts2[0][:,:,:2,:]], axis = 2)\n","model.set_weights(wts2)\n","del model2"],"metadata":{"id":"MRHbUdXirqs1"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nmkzO-vTrNIL"},"outputs":[],"source":["tf.__version__"]},{"cell_type":"markdown","metadata":{"id":"CaAfapZjDAvH"},"source":["## Set up the Trainer\n","\n","\n","---\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZjGl4mmrrNIM","cellView":"form"},"outputs":[],"source":["IMAGE_SIZE = 512 #@param {type:\"number\"}\n","BATCH_SIZE = 8 #@param {type:\"number\"}\n","NUM_CLASSES = 13 #@param {type:\"number\"}\n","DATA_DIR = \"/content/train\"\n","metadata = \"/content/flair-one_metadata.json\" \n","LR = 0.00006 #@param {type:\"number\"}\n","random_state = 42 #@param {type:\"number\"}\n","checkpoint = \"/content/gdrive/MyDrive/flair-one/models/segformer_b0_5c/segformer\" #@param {type:\"string\"}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oLnemLcwrNIS"},"outputs":[],"source":["#Define parameters for our model.\n","optim = keras.optimizers.Adam(learning_rate=LR)\n","\n","reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor = 0.5, patience = 1, min_lr=0.00001, cooldown = 4, verbose = True)\n","\n","stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose = True)\n","\n","model_checkpoint_callback  = tf.keras.callbacks.ModelCheckpoint(checkpoint, monitor='val_loss',\n","                                                                verbose=1,\n","                                                                save_best_only=True,\n","                                                                save_weights_only=True,\n","                                                                mode='min',\n","                                                                save_freq='epoch')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eiLBAn8NrNIS"},"outputs":[],"source":["# Loss\n","def dice_coef(y_true, y_pred, smooth):   \n","    y_true_f = K.flatten(tf.one_hot(y_true, depth = 13)[:,:,:,:-1])\n","    y_pred_f = K.flatten(K.softmax(y_pred, axis = -1)[:,:,:,:-1])\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    dice = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n","    return dice\n","\n","\n","def dice_coef_loss(y_true, y_pred, smooth = 100):\n","    return 1 - dice_coef(y_true, y_pred, smooth)\n","\n","\n","def mean_dice_coef(y_true, y_pred, smooth):\n","    y_true_f = tf.one_hot(y_true, depth = 13)[:,:,:,:-1]\n","    y_pred_f = K.softmax(y_pred, axis = -1)[:,:,:,:-1]\n","    intersection = K.sum(y_true_f * y_pred_f, axis = (0,1,2))\n","    dice = (2. * intersection + smooth) / (K.sum(y_true_f, axis = (0,1,2)) + K.sum(y_pred_f, axis = (0,1,2)) + smooth)\n","    return K.mean(dice[K.sum(y_true_f, axis = (0,1,2)) > 0])\n","\n","\n","def mean_dice_coef_loss(y_true, y_pred, smooth = 100):\n","    return 1 - mean_dice_coef(y_true, y_pred, smooth)\n","\n","# Metric\n","class MyMeanIOU(tf.keras.metrics.MeanIoU):\n","    def update_state(self, y_true, y_pred, sample_weight=np.array([1,1,1,1,1,1,1,1,1,1,1,1,0])):\n","        y_pred = tf.image.resize(tf.transpose(y_pred, perm = (0,2,3,1)), size=(512,512), method=\"bilinear\")\n","        #return super().update_state(tf.argmax(y_true, axis=-1), tf.argmax(y_pred, axis=-1), sample_weight)\n","        #y_true = tf.argmax(y_true, axis = -1)\n","        return super().update_state(y_true, tf.argmax(y_pred, axis=-1), tf.gather(np.array([1,1,1,1,1,1,1,1,1,1,1,1,0]), tf.cast(y_true, tf.int32)))\n","        \n","\n","metrics = [MyMeanIOU(num_classes = 13)]\n","\n","\n","def my_loss(weights):\n","    def loss(labels, logits):\n","        logits = tf.image.resize(tf.transpose(logits, perm = (0,2,3,1)), size=(512,512), method=\"bilinear\")\n","        \n","        labels = tf.cast(labels, tf.int32)\n","        return tf.compat.v1.losses.sparse_softmax_cross_entropy(labels, logits, tf.gather(weights, labels)) #tf.gather(weights, labels)\n","    return loss\n","\n","def weighted_categorical_crossentropy(weights):\n","    # weights = [0.9,0.05,0.04,0.01]\n","    def wcce(y_true, y_pred):\n","        Kweights = K.constant(weights)\n","        #y_pred = K.constant(y_pred)\n","        y_true = K.cast(y_true, y_pred.dtype)\n","        return K.categorical_crossentropy(y_true, y_pred) * K.sum(y_true * Kweights, axis=-1)\n","    return wcce"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tm_PPFndrNIT"},"outputs":[],"source":["# Compile model\n","model.compile(optimizer = optim, loss = my_loss(np.array([1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]).astype(np.float32)), metrics=[metrics])"]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"hUhLH6G5TQI9"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4r1uiEOerNIT"},"outputs":[],"source":["val_path = [(img, msk) for img, msk in val_img_paths]\n","train_path = [(img, msk) for img, msk in train_img_paths]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9I6tXH9lrNIU"},"outputs":[],"source":["train_gen = Datagen(train_path, batch_size = BATCH_SIZE, random_state = random_state, val_rate=0, train=True, transforms=train_transform) \n","val_gen = Datagen(val_path, batch_size = BATCH_SIZE, random_state = random_state, val_rate=1, train=False,transforms=test_transform)"]},{"cell_type":"code","source":["# if pretrained models...\n","# model.load_weights(checkpoint)"],"metadata":{"id":"3T2bxfVJzY9A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training\n","\n","---\n","\n"],"metadata":{"id":"y8hooLunc5Mw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"lfuGsj57rNIV"},"outputs":[],"source":["history = model.fit(\n","    train_gen,\n","    epochs = 5,\n","    verbose=1,\n","    validation_data=val_gen,\n","    callbacks = [reduce_lr, stopping, model_checkpoint_callback], \n","    use_multiprocessing=False\n",")"]},{"cell_type":"code","source":["model.load_weights(checkpoint)"],"metadata":{"id":"Kv01bl6swELc"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.7 ('tf')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"094714fe796e6c1218ad20991b7e5262c49457f2d9464e34a3ce061e080d5275"}},"colab":{"provenance":[],"machine_shape":"hm","private_outputs":true},"gpuClass":"standard","accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}